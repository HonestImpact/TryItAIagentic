# Async Work with Conversational Continuity - Implementation Plan

**Status:** Ready for Implementation
**Priority:** Phase 0 (Highest)
**Timeline:** 12-16 days
**Risk Level:** Medium (mitigated by feature flags)

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Problem Statement](#problem-statement)
3. [Design Philosophy](#design-philosophy)
4. [Architecture Overview](#architecture-overview)
5. [Implementation Phases](#implementation-phases)
6. [Code Examples](#code-examples)
7. [Testing Strategy](#testing-strategy)
8. [Rollback Plan](#rollback-plan)
9. [Success Criteria](#success-criteria)

---

## Executive Summary

### What We're Building

An async work system that lets Noah maintain conversational engagement while complex agentic work (research, tool building) runs in the background.

### The User Experience

```
User: "Can you explain React hooks and maybe build an example?"

Noah: "Hooks‚Äîgreat topic. I can walk you through concepts, and I'm
       thinking an interactive demo would help. Want me to start
       building that while we talk?"

User: "Sure"

Noah: [starts async work]
      "On it‚Äîshould be ready in ~90 seconds.

      So what prompted this? Migrating from classes or learning
      React fresh?"

[Conversation continues naturally for 60-90 seconds]

Noah: "...and that's why hooks let you compose logic without
       changing component hierarchy.

       [‚úì Custom Hooks Demo ready]

       By the way, that demo is done. Want to check it out?"
```

### Key Principles

1. **User Agency** - User decides when to kick off async work
2. **Conversational Default** - Most interactions stay conversational
3. **Perceptual Speed** - System feels fast even when work takes time
4. **Non-Breaking** - Existing functionality preserved 100%
5. **Pragmatic Agency** - Fire-and-forget works for 99% of cases

---

## Problem Statement

### Current Issue

The agentic refactor created truly intelligent agents (metacognition, learning, quality evaluation), but this sophistication takes time:

- Simple conversations: Fast (~2s)
- Complex tool building: Slow (~90-120s with full agentic workflow)

**Result:** Users wait in silence while work happens, breaking conversational flow.

### What Users Actually Need

- **Organic conversation by default** (not waiting)
- **Ability to start deep work when appropriate** (user-chosen)
- **Continued engagement during work** (no silent waiting)
- **Natural notification when work completes** (non-interruptive)

### What We're NOT Building

**NOT:** A fully bidirectional agent communication system where agents ask questions back or receive mid-flight context updates.

**WHY:** That's architecturally complex and unnecessary for 99% of use cases. Context staleness rarely matters:
- 90% of cases: Context doesn't change during work
- 9% of cases: Minor changes, deliverable still useful
- 1% of cases: Significant change, user can request revision

**Building for the 99%, not the 1%.**

---

## Design Philosophy

### Architecture Trade-offs

| Aspect | Complex Approach | Pragmatic Approach (Chosen) |
|--------|------------------|---------------------------|
| **Context Updates** | Streaming context to agent | Fire-and-forget with initial context |
| **Agent Questions** | Agent can ask back | Agent works with initial context |
| **State Management** | Full persistence (Redis) | In-memory with graceful degradation |
| **Cancellation** | Mid-flight cancellation | Basic cancellation support |
| **Timeline** | 3-4 weeks | 12-16 days |
| **Complexity** | High | Medium |
| **Edge Case Coverage** | 100% | 99% |
| **User Experience** | Perfect | Excellent |

**Decision:** Choose pragmatic approach. Ship faster, handle 99% of cases, enhance later if needed.

### Perceptual Speed Techniques

We use several techniques to make async work *feel* fast:

1. **Immediate Streaming** - Start responding <500ms always
2. **Progressive Updates** - Talk during work (don't go silent)
3. **Optimistic UI** - Show placeholder immediately
4. **Conversational Continuity** - Stay engaged, don't wait
5. **Smart Notifications** - Deliver results at natural pauses

**Result:** 90 seconds that feels like 30 seconds.

### Tiered Response Strategy

Not everything needs deep agentic work:

| Tier | Request Type | Speed | Pattern |
|------|-------------|-------|---------|
| **1** | Simple conversation | <2s | Direct Noah response |
| **2** | Simple tool | 5-15s | Fast path (skip agentic) |
| **3** | Complex work | 30-90s | Async with conversation |
| **4** | Deep work | 2-5min | User-requested, progress shown |

**Implementation focuses on Tier 3** (Async with conversation).

---

## Architecture Overview

### System Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Chat Route                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  1. Async Opportunity Detector                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     ‚Üì                                           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  2. Session Manager (track offers/confirmations)‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     ‚Üì                                           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  3. Confirmation Detector                       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     ‚Üì                                           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  4. Async Work Queue (enqueue work)            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     ‚Üì                                           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  5. Noah Response (with context injection)      ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Async Work Queue     ‚îÇ
              ‚îÇ  (background process) ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Existing Agents      ‚îÇ
              ‚îÇ  (Tinkerer/Wanderer) ‚îÇ
              ‚îÇ  [No changes needed]  ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

```
1. User Message
   ‚Üì
2. Detect Async Opportunity
   ‚Üì
3a. If Opportunity ‚Üí Offer to User (in Noah's response)
3b. If No Opportunity ‚Üí Normal response
   ‚Üì
4. User Confirms
   ‚Üì
5. Queue Async Work (fire-and-forget)
   ‚Üì
6. Noah Continues Conversation
   ‚Üì
7. Async Work Completes (60-90s later)
   ‚Üì
8. Next User Message ‚Üí Notification Injected
```

### Key Design Decisions

**1. Session State: In-Memory (with graceful degradation)**

**Decision:** Use in-memory Map for session state
**Rationale:**
- Simpler implementation (no Redis dependency)
- Acceptable trade-off: Server restart loses offers (minor issue)
- Session typically lasts <30 minutes (restart unlikely mid-session)
- Future: Can add Redis without changing interface

**2. Context: Static Snapshot (fire-and-forget)**

**Decision:** Agent works with initial context, no mid-flight updates
**Rationale:**
- Works correctly 99% of the time
- Much simpler than streaming context
- Failed 1% can request "revise this"
- Future: Can add context streaming if needed

**3. Notifications: Poll-based (not push)**

**Decision:** Check for completed work at start of each user message
**Rationale:**
- Simpler than websocket push
- Natural timing (user is already engaged)
- No additional infrastructure
- Acceptable delay (user sends message ‚Üí notified)

**4. Agents: Unchanged (call existing methods)**

**Decision:** Async work calls existing agent.handleRequest()
**Rationale:**
- Zero changes to agent code
- All agentic behavior preserved (metacognition, learning, etc.)
- Existing tests still pass
- Agent doesn't know it's running async (doesn't need to)

---

## Implementation Phases

### Phase 1: Tiered Response Foundation (3-4 days)

**Goal:** Add smart routing before async work

**Why First:** Need to identify which requests should even offer async work.

**Tasks:**

1. **Create Request Classifier**

```typescript
// src/lib/request-classifier.ts

export enum RequestTier {
  SIMPLE_CONVERSATION = 'simple_conversation',  // <2s
  SIMPLE_TOOL = 'simple_tool',                  // 5-15s
  COMPLEX_WORK = 'complex_work',                // 30-90s async candidate
  DEEP_WORK = 'deep_work'                       // 2-5min, user-requested
}

export interface RequestClassification {
  tier: RequestTier;
  confidence: number;
  reasoning: string;
}

/**
 * Classify request to determine appropriate handling tier
 */
export async function classifyRequest(
  request: string
): Promise<RequestClassification> {
  // Simple conversation patterns (no LLM needed)
  const conversationPatterns = [
    /^(what|how|why|when|where|who|explain|tell me)/i,
    /^(can you explain|help me understand)/i,
    /\?$/  // Ends with question mark
  ];

  if (conversationPatterns.some(p => p.test(request))) {
    return {
      tier: RequestTier.SIMPLE_CONVERSATION,
      confidence: 0.9,
      reasoning: 'Question/explanation request'
    };
  }

  // Simple tools (pattern matching)
  const simpleToolPatterns = [
    /^(build|create|make)\s+(a|an)?\s*(calculator|timer|stopwatch|counter)$/i,
    /^(calculator|timer|stopwatch|counter)$/i
  ];

  if (simpleToolPatterns.some(p => p.test(request))) {
    return {
      tier: RequestTier.SIMPLE_TOOL,
      confidence: 0.95,
      reasoning: 'Simple, well-defined tool'
    };
  }

  // Complex work indicators
  const complexIndicators = [
    /dashboard/i,
    /interactive.*chart/i,
    /complex|sophisticated|advanced/i,
    /multiple.*(?:features|components)/i,
    /real-time/i,
    /research.*(?:best practices|approaches|options)/i
  ];

  if (complexIndicators.some(p => p.test(request))) {
    return {
      tier: RequestTier.COMPLEX_WORK,
      confidence: 0.8,
      reasoning: 'Complex work requiring thought/research'
    };
  }

  // Default: conversation
  return {
    tier: RequestTier.SIMPLE_CONVERSATION,
    confidence: 0.6,
    reasoning: 'Default classification'
  };
}
```

2. **Integrate Classification into Chat Route**

```typescript
// src/app/api/chat/route.ts

import { classifyRequest, RequestTier } from '@/lib/request-classifier';

// Early in chat handler, after security validation:
const classification = await classifyRequest(userMessage);

logger.info('Request classified', {
  tier: classification.tier,
  confidence: classification.confidence,
  reasoning: classification.reasoning
});

// Route based on tier
switch (classification.tier) {
  case RequestTier.SIMPLE_CONVERSATION:
    // Direct Noah response (existing fast path)
    return await handleSimpleConversation(userMessage);

  case RequestTier.SIMPLE_TOOL:
    // Fast tool generation (skip agentic workflow)
    return await handleSimpleTool(userMessage);

  case RequestTier.COMPLEX_WORK:
    // Offer async work (Phase 3)
    return await handleComplexWork(userMessage);

  case RequestTier.DEEP_WORK:
    // Future: Explicit deep work with progress
    return await handleDeepWork(userMessage);
}
```

3. **Implement Fast Tool Generation**

```typescript
// src/lib/fast-tool-generator.ts

/**
 * Fast tool generation for simple, well-defined tools
 * Skips full agentic workflow, uses proven templates
 */
export async function generateSimpleTool(
  request: string,
  llmProvider: LLMProvider
): Promise<AgentResponse> {
  // Extract tool type
  const toolType = extractToolType(request); // 'calculator', 'timer', etc.

  // Load proven pattern (from pattern library)
  const pattern = await loadPattern(toolType);

  // Simple generation (no metacognition, no beauty check)
  const result = await llmProvider.generateText({
    messages: [{
      role: 'user',
      content: `Create a ${toolType} using this proven pattern as foundation:
                ${pattern}

                Keep it simple, functional, clean. No overthinking.`
    }],
    temperature: 0.3,
    maxTokens: 2000
  });

  return {
    content: result.content,
    agentName: 'tinkerer',
    confidence: 0.85, // Proven patterns = high confidence
    metadata: {
      fastPath: true,
      pattern: toolType
    }
  };
}

// Helper
function extractToolType(request: string): string {
  const match = request.match(/(calculator|timer|stopwatch|counter)/i);
  return match ? match[1].toLowerCase() : 'calculator';
}
```

**Testing Phase 1:**

```bash
# Test classification accuracy
npm test -- request-classifier.test.ts

# Test fast tool generation
npm test -- fast-tool-generator.test.ts

# Integration test
tests/test-tiered-responses.sh
```

**Success Criteria:**
- ‚úÖ Classification works (>90% accuracy on test set)
- ‚úÖ Fast tools generate in <15s
- ‚úÖ Quality comparable to full agentic (for simple tools)
- ‚úÖ All existing tests still pass

---

### Phase 2: Perceptual Speed (2-3 days)

**Goal:** Make everything feel faster through streaming and progress updates

**Why Second:** Independent of async work, benefits all tiers

**Tasks:**

1. **Implement Immediate Streaming**

```typescript
// src/lib/streaming-response.ts

/**
 * Start streaming response immediately (<500ms)
 */
export class StreamingResponseBuilder {
  private encoder = new TextEncoder();
  private stream: TransformStream;

  constructor() {
    this.stream = new TransformStream();
  }

  /**
   * Send immediate acknowledgment
   */
  async acknowledge(request: string): Promise<void> {
    const ack = this.generateAcknowledgment(request);
    await this.send(ack);
  }

  /**
   * Send chunk to stream
   */
  private async send(text: string): Promise<void> {
    const writer = this.stream.writable.getWriter();
    await writer.write(this.encoder.encode(text));
    writer.releaseLock();
  }

  /**
   * Generate contextual acknowledgment
   */
  private generateAcknowledgment(request: string): string {
    const acks = [
      "Got it, let me help with that...",
      "Okay, working on this...",
      "Sure thing...",
      "Let me take a look at that..."
    ];
    return acks[Math.floor(Math.random() * acks.length)];
  }

  /**
   * Send progress update
   */
  async progress(message: string): Promise<void> {
    await this.send(`\n\n${message}`);
  }

  /**
   * Complete stream
   */
  async complete(finalContent: string): Promise<void> {
    await this.send(`\n\n${finalContent}`);
    const writer = this.stream.writable.getWriter();
    await writer.close();
  }

  getReadableStream(): ReadableStream {
    return this.stream.readable;
  }
}
```

2. **Update Chat Route for Streaming**

```typescript
// src/app/api/chat/route.ts

export async function POST(req: NextRequest) {
  // ... existing setup ...

  // Create streaming response
  const responseStream = new StreamingResponseBuilder();

  // Start streaming immediately (<500ms)
  await responseStream.acknowledge(userMessage);

  // Work in parallel
  const workPromise = handleRequest(userMessage);

  // Send progress updates every 20-30s
  const progressInterval = setInterval(() => {
    if (!workCompleted) {
      responseStream.progress(getContextualProgress());
    }
  }, 25000); // 25 seconds

  // Wait for work
  const result = await workPromise;
  clearInterval(progressInterval);

  // Send final result
  await responseStream.complete(result.content);

  return new Response(responseStream.getReadableStream(), {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive'
    }
  });
}

function getContextualProgress(): string {
  const updates = [
    "Still thinking this through...",
    "Getting closer...",
    "Almost there...",
    "Putting the pieces together..."
  ];
  return updates[Math.floor(Math.random() * updates.length)];
}
```

3. **Add Progress Updates to Agents**

```typescript
// src/lib/agents/practical-agent-agentic.ts

// In generation node
private async generationNode(state: TinkererState): Promise<Partial<TinkererState>> {
  // Send progress update if streaming available
  if (this.streamingCallback) {
    await this.streamingCallback('Building implementation...');
  }

  // ... existing generation logic ...
}

// In evaluation node
private async selfEvaluationNode(state: TinkererState): Promise<Partial<TinkererState>> {
  if (this.streamingCallback) {
    await this.streamingCallback('Evaluating quality...');
  }

  // ... existing evaluation logic ...
}
```

**Testing Phase 2:**

```bash
# Test streaming response
npm test -- streaming-response.test.ts

# Manual test: Verify <500ms first response
curl -N http://localhost:5000/api/chat -d '{"messages":[...]}'

# Measure perceived speed
tests/test-perceptual-speed.sh
```

**Success Criteria:**
- ‚úÖ First bytes stream <500ms
- ‚úÖ Progress updates every 20-30s
- ‚úÖ Users perceive 2x faster (survey/feedback)
- ‚úÖ No regression in actual speed

---

### Phase 3: Async Opportunity Detection (1-2 days)

**Goal:** Detect when requests could benefit from async work

**Tasks:**

1. **Create Async Opportunity Detector**

```typescript
// src/lib/async-opportunity-detector.ts

export interface AsyncOpportunity {
  shouldOffer: boolean;
  type: 'research' | 'tool' | null;
  suggestion: string;
  estimatedDuration: number; // seconds
}

/**
 * Detect if request could benefit from async work
 */
export function detectAsyncOpportunity(
  request: string,
  classification: RequestClassification
): AsyncOpportunity {
  // Only offer async for COMPLEX_WORK tier
  if (classification.tier !== RequestTier.COMPLEX_WORK) {
    return {
      shouldOffer: false,
      type: null,
      suggestion: '',
      estimatedDuration: 0
    };
  }

  // Tool building indicators
  const toolPatterns = [
    /build|create|make.*(?:dashboard|chart|visualization|app)/i,
    /interactive.*(?:tool|demo|example)/i,
    /(?:complex|sophisticated).*(?:component|interface)/i
  ];

  if (toolPatterns.some(p => p.test(request))) {
    return {
      shouldOffer: true,
      type: 'tool',
      suggestion: "I can start building that in the background while we talk through what you need",
      estimatedDuration: 90
    };
  }

  // Research indicators
  const researchPatterns = [
    /research|investigate|explore|analyze/i,
    /compare.*(?:options|frameworks|libraries|approaches)/i,
    /what are the.*(?:best practices|latest|current trends)/i,
    /(?:comprehensive|detailed).*(?:overview|analysis)/i
  ];

  if (researchPatterns.some(p => p.test(request))) {
    return {
      shouldOffer: true,
      type: 'research',
      suggestion: "I can kick off some research on that while we discuss what you're trying to accomplish",
      estimatedDuration: 30
    };
  }

  // No async opportunity
  return {
    shouldOffer: false,
    type: null,
    suggestion: '',
    estimatedDuration: 0
  };
}
```

2. **Integrate Detection (Logging Only First)**

```typescript
// src/app/api/chat/route.ts

// After classification
const asyncOpp = detectAsyncOpportunity(userMessage, classification);

if (asyncOpp.shouldOffer) {
  logger.info('üîç Async opportunity detected', {
    type: asyncOpp.type,
    estimatedDuration: asyncOpp.estimatedDuration,
    suggestion: asyncOpp.suggestion
  });

  // Don't act on it yet - just log for verification
}
```

**Testing Phase 3:**

```bash
# Test detection accuracy
npm test -- async-opportunity-detector.test.ts

# Manual verification: Check logs
tests/test-async-detection-logging.sh
```

**Success Criteria:**
- ‚úÖ Detects appropriate opportunities (>85% precision)
- ‚úÖ Low false positives (<10%)
- ‚úÖ Logs show correct classification

---

### Phase 4: Session State Management (1 day)

**Goal:** Track async offers and confirmations per session

**Tasks:**

1. **Create Session Manager**

```typescript
// src/lib/session-manager.ts

interface AsyncOffer {
  type: 'research' | 'tool';
  request: string;
  suggestion: string;
  offeredAt: Date;
}

interface SessionState {
  sessionId: string;
  lastOffer?: AsyncOffer;
  activeWork?: string[]; // workIds
  createdAt: Date;
  lastActivity: Date;
}

class SessionManager {
  private sessions: Map<string, SessionState> = new Map();
  private readonly SESSION_TIMEOUT = 30 * 60 * 1000; // 30 minutes

  constructor() {
    // Clean up expired sessions every 5 minutes
    setInterval(() => this.cleanup(), 5 * 60 * 1000);
  }

  /**
   * Get or create session state
   */
  private getOrCreate(sessionId: string): SessionState {
    let session = this.sessions.get(sessionId);

    if (!session) {
      session = {
        sessionId,
        createdAt: new Date(),
        lastActivity: new Date(),
        activeWork: []
      };
      this.sessions.set(sessionId, session);
    } else {
      session.lastActivity = new Date();
    }

    return session;
  }

  /**
   * Store async offer for session
   */
  setLastOffer(sessionId: string, offer: AsyncOffer): void {
    const session = this.getOrCreate(sessionId);
    session.lastOffer = {
      ...offer,
      offeredAt: new Date()
    };
  }

  /**
   * Get last offer for session
   */
  getLastOffer(sessionId: string): AsyncOffer | null {
    const session = this.sessions.get(sessionId);

    if (!session?.lastOffer) return null;

    // Expire offers after 5 minutes
    const age = Date.now() - session.lastOffer.offeredAt.getTime();
    if (age > 5 * 60 * 1000) {
      delete session.lastOffer;
      return null;
    }

    return session.lastOffer;
  }

  /**
   * Clear last offer (after confirmation)
   */
  clearLastOffer(sessionId: string): void {
    const session = this.sessions.get(sessionId);
    if (session) {
      delete session.lastOffer;
    }
  }

  /**
   * Add active work to session
   */
  addActiveWork(sessionId: string, workId: string): void {
    const session = this.getOrCreate(sessionId);
    if (!session.activeWork) session.activeWork = [];
    session.activeWork.push(workId);
  }

  /**
   * Remove completed work from session
   */
  removeActiveWork(sessionId: string, workId: string): void {
    const session = this.sessions.get(sessionId);
    if (session?.activeWork) {
      session.activeWork = session.activeWork.filter(id => id !== workId);
    }
  }

  /**
   * Get active work for session
   */
  getActiveWork(sessionId: string): string[] {
    return this.sessions.get(sessionId)?.activeWork || [];
  }

  /**
   * Clean up expired sessions
   */
  private cleanup(): void {
    const now = Date.now();
    const expired: string[] = [];

    for (const [sessionId, session] of this.sessions.entries()) {
      const age = now - session.lastActivity.getTime();
      if (age > this.SESSION_TIMEOUT) {
        expired.push(sessionId);
      }
    }

    expired.forEach(sessionId => {
      this.sessions.delete(sessionId);
      logger.info('Session expired and cleaned up', { sessionId });
    });
  }
}

// Singleton instance
export const sessionManager = new SessionManager();
```

**Testing Phase 4:**

```bash
# Test session management
npm test -- session-manager.test.ts

# Test expiration
npm test -- session-expiration.test.ts
```

**Success Criteria:**
- ‚úÖ Sessions created and retrieved correctly
- ‚úÖ Offers expire after 5 minutes
- ‚úÖ Sessions clean up after 30 minutes
- ‚úÖ No memory leaks

---

### Phase 5: Offer Injection (1-2 days)

**Goal:** Noah offers async work naturally in responses

**Tasks:**

1. **Add Offer Context to Noah's Prompt**

```typescript
// src/app/api/chat/route.ts

if (asyncOpp.shouldOffer) {
  // Store offer in session
  sessionManager.setLastOffer(sessionId, {
    type: asyncOpp.type,
    request: userMessage,
    suggestion: asyncOpp.suggestion
  });

  // Add context to Noah's system prompt
  const asyncOfferContext = `
ASYNC WORK OPPORTUNITY:
The user's request could benefit from ${asyncOpp.type} work that will take
approximately ${asyncOpp.estimatedDuration} seconds.

OFFER THIS NATURALLY:
${asyncOpp.suggestion}

Example phrasing:
"I can walk you through [topic] and I'm also thinking [result] would help
solidify this. Want me to start ${asyncOpp.type === 'tool' ? 'building' : 'researching'}
that while we talk?"

IMPORTANT:
- Be conversational and natural
- Give them a choice, don't assume they want async work
- If they decline or ignore, continue conversation normally
- Don't be pushy or salesy
  `;

  // Append to system prompt (don't replace)
  systemPrompt += '\n\n' + asyncOfferContext;
}
```

2. **Generate Noah's Response with Offer**

```typescript
// Noah's response now naturally includes the offer
const response = await generateNoahResponse({
  messages: conversationHistory,
  systemPrompt: systemPrompt, // Includes async offer context
  streaming: true
});

return response;
```

**Testing Phase 5:**

```bash
# Test offer injection
tests/test-async-offer-injection.sh

# Verify Noah's tone (manual)
# - Should feel natural
# - Should give choice
# - Should not be pushy
```

**Success Criteria:**
- ‚úÖ Noah offers async work naturally
- ‚úÖ Tone is conversational, not salesy
- ‚úÖ Offers include suggestion
- ‚úÖ If user ignores, conversation continues normally

---

### Phase 6: Confirmation Detection (1 day)

**Goal:** Detect when user confirms async work offer

**Tasks:**

1. **Create Confirmation Detector**

```typescript
// src/lib/confirmation-detector.ts

/**
 * Detect if user is confirming async work
 */
export function detectConfirmation(message: string): boolean {
  const confirmationPatterns = [
    /^yes$/i,
    /^yeah$/i,
    /^yep$/i,
    /^sure$/i,
    /^ok$/i,
    /^okay$/i,
    /^go ahead$/i,
    /^do it$/i,
    /^start it$/i,
    /^start.*(?:building|working|researching)/i,
    /^build it$/i,
    /^sounds good$/i
  ];

  const trimmed = message.trim().toLowerCase();

  // Check exact matches and patterns
  return confirmationPatterns.some(pattern => pattern.test(trimmed));
}
```

2. **Handle Confirmation in Chat Route**

```typescript
// src/app/api/chat/route.ts

// After classification, check for confirmation
const lastOffer = sessionManager.getLastOffer(sessionId);
const isConfirming = lastOffer && detectConfirmation(userMessage);

if (isConfirming) {
  logger.info('‚úÖ User confirmed async work', {
    sessionId,
    type: lastOffer.type,
    request: lastOffer.request
  });

  // Add acknowledgment context to Noah's response
  const ackContext = `
USER CONFIRMED ASYNC WORK:
The user just confirmed they want you to start ${lastOffer.type} work
in the background.

ACKNOWLEDGE BRIEFLY:
- "On it. Should take about ${asyncOpp.estimatedDuration} seconds..."
- "Great, starting that now..."
- Or similar brief acknowledgment

THEN CONTINUE CONVERSATION:
Ask questions, explore their needs, provide value. Don't just say
"working on it" and go silent. This is a conversation.
  `;

  systemPrompt += '\n\n' + ackContext;

  // Clear offer (it's been accepted)
  sessionManager.clearLastOffer(sessionId);

  // Mark that we need to queue work (Phase 7)
  shouldQueueWork = true;
}
```

**Testing Phase 6:**

```bash
# Test confirmation detection
npm test -- confirmation-detector.test.ts

# Test false positives
# Ensure "yes" to different question doesn't trigger
tests/test-confirmation-false-positives.sh
```

**Success Criteria:**
- ‚úÖ Detects confirmations correctly (>95% precision)
- ‚úÖ Low false positives (<5%)
- ‚úÖ Noah acknowledges confirmation naturally
- ‚úÖ Conversation continues after confirmation

---

### Phase 7: Async Work Queue (2-3 days)

**Goal:** Queue and execute async work in background

**Tasks:**

1. **Create Async Work Queue**

```typescript
// src/lib/async-work-queue.ts

interface AsyncWork {
  id: string;
  sessionId: string;
  type: 'research' | 'tool';
  request: string;
  status: 'queued' | 'in_progress' | 'completed' | 'failed';
  result?: any;
  error?: string;
  startedAt: Date;
  completedAt?: Date;
  estimatedDuration: number;
}

class AsyncWorkQueue {
  private queue: Map<string, AsyncWork> = new Map();
  private readonly MAX_CONCURRENT = 5; // Per server
  private currentlyProcessing = 0;

  /**
   * Enqueue async work
   */
  async enqueue(work: Omit<AsyncWork, 'id' | 'status' | 'startedAt'>): Promise<string> {
    const workId = `work_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    const asyncWork: AsyncWork = {
      ...work,
      id: workId,
      status: 'queued',
      startedAt: new Date()
    };

    this.queue.set(workId, asyncWork);

    logger.info('üîÑ Async work queued', {
      workId,
      type: work.type,
      sessionId: work.sessionId,
      estimatedDuration: work.estimatedDuration
    });

    // Start processing (fire-and-forget, don't await)
    this.processWork(workId).catch(error => {
      logger.error('Async work processing failed', { workId, error });
    });

    return workId;
  }

  /**
   * Process work in background
   */
  private async processWork(workId: string): Promise<void> {
    const work = this.queue.get(workId);
    if (!work) return;

    // Wait if too many concurrent
    while (this.currentlyProcessing >= this.MAX_CONCURRENT) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }

    this.currentlyProcessing++;
    work.status = 'in_progress';

    logger.info('‚öôÔ∏è  Async work started', {
      workId,
      type: work.type,
      concurrent: this.currentlyProcessing
    });

    try {
      // Set timeout
      const timeoutMs = work.estimatedDuration * 1000 * 2; // 2x estimated
      const resultPromise = this.executeWork(work);
      const timeoutPromise = new Promise((_, reject) =>
        setTimeout(() => reject(new Error('Work timeout')), timeoutMs)
      );

      // Race timeout
      work.result = await Promise.race([resultPromise, timeoutPromise]);
      work.status = 'completed';
      work.completedAt = new Date();

      const duration = work.completedAt.getTime() - work.startedAt.getTime();
      logger.info('‚úÖ Async work completed', {
        workId,
        type: work.type,
        durationMs: duration,
        durationS: (duration / 1000).toFixed(1)
      });

    } catch (error) {
      work.status = 'failed';
      work.error = error instanceof Error ? error.message : 'Unknown error';

      logger.error('‚ùå Async work failed', {
        workId,
        type: work.type,
        error: work.error
      });
    } finally {
      this.currentlyProcessing--;
    }
  }

  /**
   * Execute work using existing agents
   */
  private async executeWork(work: AsyncWork): Promise<any> {
    // Import agents (circular dependency handled by dynamic import)
    const { tinkererInstance, wandererInstance } = await import('./agents-cache');

    if (work.type === 'tool') {
      // Call existing Tinkerer agent (no changes needed to agent)
      const result = await tinkererInstance.handleRequest({
        content: work.request,
        sessionId: work.sessionId,
        requestId: work.id
      });
      return result;

    } else if (work.type === 'research') {
      // Call existing Wanderer agent
      const result = await wandererInstance.handleRequest({
        content: work.request,
        sessionId: work.sessionId,
        requestId: work.id
      });
      return result;
    }

    throw new Error(`Unknown work type: ${work.type}`);
  }

  /**
   * Get work status
   */
  getStatus(workId: string): AsyncWork | undefined {
    return this.queue.get(workId);
  }

  /**
   * Get completed work for session
   */
  getCompletedWork(sessionId: string): AsyncWork[] {
    return Array.from(this.queue.values())
      .filter(w => w.sessionId === sessionId && w.status === 'completed');
  }

  /**
   * Get active work for session
   */
  getActiveWork(sessionId: string): AsyncWork[] {
    return Array.from(this.queue.values())
      .filter(w =>
        w.sessionId === sessionId &&
        (w.status === 'queued' || w.status === 'in_progress')
      );
  }

  /**
   * Clear completed work from queue
   */
  clearCompleted(sessionId: string): void {
    const completed = this.getCompletedWork(sessionId);
    completed.forEach(work => {
      this.queue.delete(work.id);
      sessionManager.removeActiveWork(sessionId, work.id);
    });
  }

  /**
   * Cancel work (basic support)
   */
  cancel(workId: string): boolean {
    const work = this.queue.get(workId);
    if (!work) return false;

    if (work.status === 'queued') {
      // Can cancel queued work
      this.queue.delete(workId);
      logger.info('üö´ Async work cancelled (was queued)', { workId });
      return true;
    }

    if (work.status === 'in_progress') {
      // Can't stop in-progress work, but mark as cancelled
      work.status = 'failed';
      work.error = 'Cancelled by user';
      logger.info('üö´ Async work marked cancelled (was in progress)', { workId });
      return true;
    }

    return false;
  }
}

// Singleton
export const asyncWorkQueue = new AsyncWorkQueue();
```

2. **Queue Work on Confirmation**

```typescript
// src/app/api/chat/route.ts

if (isConfirming && lastOffer) {
  // Queue the work
  const workId = await asyncWorkQueue.enqueue({
    sessionId,
    type: lastOffer.type,
    request: lastOffer.request,
    estimatedDuration: asyncOpp.estimatedDuration
  });

  // Track in session
  sessionManager.addActiveWork(sessionId, workId);

  logger.info('üîÑ Async work queued for session', {
    sessionId,
    workId,
    type: lastOffer.type
  });
}
```

3. **Add Feature Flag**

```typescript
// .env
ENABLE_ASYNC_WORK=true  # Can disable instantly if issues

// src/lib/feature-flags.ts
export const FEATURES = {
  asyncWork: process.env.ENABLE_ASYNC_WORK === 'true'
};

// Wrap all async work in feature flag
if (FEATURES.asyncWork && isConfirming && lastOffer) {
  // ... queue work ...
}
```

**Testing Phase 7:**

```bash
# Test queue operations
npm test -- async-work-queue.test.ts

# Test concurrent work limits
npm test -- async-work-concurrency.test.ts

# Test timeout handling
npm test -- async-work-timeout.test.ts

# Integration test
tests/test-async-work-execution.sh
```

**Success Criteria:**
- ‚úÖ Work queues successfully
- ‚úÖ Work executes in background
- ‚úÖ Concurrent limits enforced
- ‚úÖ Timeouts handled gracefully
- ‚úÖ Agents called correctly (existing tests still pass)

---

### Phase 8: Result Notification (1-2 days)

**Goal:** Notify user when async work completes

**Tasks:**

1. **Poll for Completed Work**

```typescript
// src/app/api/chat/route.ts

// At START of each request handler (before routing)
if (FEATURES.asyncWork) {
  const completedWork = asyncWorkQueue.getCompletedWork(sessionId);

  if (completedWork.length > 0) {
    logger.info('üì¨ Completed async work found', {
      sessionId,
      count: completedWork.length,
      types: completedWork.map(w => w.type)
    });

    // Build notification context
    const notifications = completedWork.map(w => {
      const type = w.type === 'tool' ? 'Tool' : 'Research';
      const title = w.result?.title || w.request.substring(0, 50);
      const duration = w.completedAt
        ? Math.round((w.completedAt.getTime() - w.startedAt.getTime()) / 1000)
        : 0;

      return {
        type,
        title,
        duration,
        fullRequest: w.request
      };
    });

    // Inject notification context into Noah's response
    const notificationContext = `
BACKGROUND WORK COMPLETED:
${notifications.map((n, i) => `
${i + 1}. ${n.type}: "${n.title}" (completed in ${n.duration}s)
   Original request: "${n.fullRequest}"
`).join('\n')}

NOTIFY USER NATURALLY:
- Don't interrupt the current conversation awkwardly
- Find a natural moment to mention it
- Example: "By the way, that [tool/research] is ready..."
- Or weave it into your response to their current question
- Be conversational, not robotic

If user's current question is unrelated, you can say:
"[Answer their question]...
 Oh, and that [tool/research] I was working on is ready. Want to check it out?"

If user's current question is related, mention it more directly:
"Good question. That actually relates to the [tool/research] I just finished..."
    `;

    systemPrompt += '\n\n' + notificationContext;

    // Store results in session for retrieval
    completedWork.forEach(w => {
      sessionArtifacts.set(w.id, {
        title: w.result?.title || 'Generated Tool',
        content: w.result?.content || w.result,
        timestamp: w.completedAt?.getTime() || Date.now(),
        agent: w.type === 'tool' ? 'tinkerer' : 'wanderer',
        id: w.id
      });
    });

    // Clear from queue
    asyncWorkQueue.clearCompleted(sessionId);
  }
}
```

2. **Add Smart Notification Timing (Optional Enhancement)**

```typescript
// src/lib/smart-notification.ts

/**
 * Determine if now is a good time to notify
 */
export function shouldNotifyNow(
  conversationContext: string,
  completedWork: AsyncWork[]
): boolean {
  // Don't interrupt deep technical explanations
  const deepExplanationPatterns = [
    /here's how.*works/i,
    /let me explain/i,
    /the key concept/i,
    /to understand this/i
  ];

  if (deepExplanationPatterns.some(p => p.test(conversationContext))) {
    return false; // Defer notification
  }

  // Check if current topic is related to completed work
  const isRelated = completedWork.some(w =>
    conversationContext.toLowerCase().includes(w.type) ||
    conversationContext.toLowerCase().includes(w.request.substring(0, 20).toLowerCase())
  );

  if (isRelated) {
    return true; // Highly relevant, notify now
  }

  // Default: notify at next message (natural pause)
  return true;
}
```

**Testing Phase 8:**

```bash
# Test notification detection
npm test -- notification.test.ts

# Test notification timing
tests/test-notification-timing.sh

# Integration test: Full flow
tests/test-async-work-full-flow.sh
```

**Success Criteria:**
- ‚úÖ Completed work detected correctly
- ‚úÖ Noah notifies naturally (not awkwardly)
- ‚úÖ Results available in session artifacts
- ‚úÖ Timing feels appropriate

---

### Phase 9: Conversational Continuity (1 day)

**Goal:** Noah stays engaged during async work

**Tasks:**

1. **Add Active Work Context**

```typescript
// src/app/api/chat/route.ts

if (FEATURES.asyncWork) {
  const activeWork = asyncWorkQueue.getActiveWork(sessionId);

  if (activeWork.length > 0) {
    logger.info('‚öôÔ∏è  Active async work in progress', {
      sessionId,
      count: activeWork.length,
      workIds: activeWork.map(w => w.id)
    });

    const continuityContext = `
BACKGROUND WORK IN PROGRESS:
${activeWork.map((w, i) => `
${i + 1}. ${w.type}: "${w.request.substring(0, 50)}..." (started ${Math.floor((Date.now() - w.startedAt.getTime()) / 1000)}s ago)
`).join('\n')}

CONVERSATIONAL CONTINUITY:
You have background work running, but DON'T:
- Mention it unless directly relevant
- Remind user it's working (they know)
- Apologize for the wait
- Say "still working on that"

DO:
- Continue being conversational and helpful
- Answer their questions fully
- Explore their needs
- Provide value in the conversation
- Stay engaged and present

The background work will notify when complete. Your job is to make
this conversation valuable while it runs.
    `;

    systemPrompt += '\n\n' + continuityContext;
  }
}
```

2. **Add Optional Progress Mentions (Natural)**

```typescript
// Optional: If user asks about progress
const progressQuestionPatterns = [
  /how's that.*going/i,
  /is it done/i,
  /ready yet/i,
  /still working/i
];

if (progressQuestionPatterns.some(p => p.test(userMessage))) {
  const activeWork = asyncWorkQueue.getActiveWork(sessionId);

  if (activeWork.length > 0) {
    const elapsed = Math.floor((Date.now() - activeWork[0].startedAt.getTime()) / 1000);
    const estimated = activeWork[0].estimatedDuration;
    const remaining = Math.max(0, estimated - elapsed);

    const progressContext = `
USER ASKED ABOUT PROGRESS:
Work has been running for ${elapsed} seconds.
Estimated total: ${estimated} seconds.
Roughly ${remaining} seconds remaining.

RESPOND NATURALLY:
Don't give robotic status. Be conversational:
- "Almost there - probably another 30 seconds or so..."
- "Should be wrapping up in the next minute..."
- Or similar natural language
    `;

    systemPrompt += '\n\n' + progressContext;
  }
}
```

**Testing Phase 9:**

```bash
# Test conversational continuity
tests/test-conversational-continuity.sh

# Manual: Verify Noah stays engaged
# - Send messages during async work
# - Verify responses are conversational
# - Verify no awkward "still working" mentions
```

**Success Criteria:**
- ‚úÖ Noah stays conversational during async work
- ‚úÖ Doesn't awkwardly mention background work
- ‚úÖ Responds helpfully to progress questions
- ‚úÖ Conversation feels natural

---

## Code Examples

### Complete Chat Route Integration

```typescript
// src/app/api/chat/route.ts

import { FEATURES } from '@/lib/feature-flags';
import { classifyRequest, RequestTier } from '@/lib/request-classifier';
import { detectAsyncOpportunity } from '@/lib/async-opportunity-detector';
import { detectConfirmation } from '@/lib/confirmation-detector';
import { sessionManager } from '@/lib/session-manager';
import { asyncWorkQueue } from '@/lib/async-work-queue';
import { StreamingResponseBuilder } from '@/lib/streaming-response';

export async function POST(req: NextRequest) {
  const { messages, sessionId } = await req.json();
  const userMessage = messages[messages.length - 1].content;

  // Create streaming response
  const responseStream = new StreamingResponseBuilder();

  // Start streaming immediately
  await responseStream.acknowledge(userMessage);

  try {
    // Security validation (existing)
    const securityCheck = await securityService.validate(userMessage);
    if (securityCheck.blocked) {
      return handleSecurityBlock(securityCheck);
    }

    // Check for completed async work FIRST
    if (FEATURES.asyncWork) {
      const completedWork = asyncWorkQueue.getCompletedWork(sessionId);
      if (completedWork.length > 0) {
        // Add notification context (see Phase 8)
        systemPrompt += buildNotificationContext(completedWork);
        asyncWorkQueue.clearCompleted(sessionId);
      }
    }

    // Classify request
    const classification = await classifyRequest(userMessage);
    logger.info('Request classified', { tier: classification.tier });

    // Handle based on tier
    if (classification.tier === RequestTier.SIMPLE_CONVERSATION) {
      // Fast path: Direct Noah response
      const response = await noah.respond(userMessage);
      await responseStream.complete(response.content);
      return new Response(responseStream.getReadableStream());
    }

    if (classification.tier === RequestTier.SIMPLE_TOOL) {
      // Fast tool generation
      await responseStream.progress('Building that for you...');
      const tool = await generateSimpleTool(userMessage);
      await responseStream.complete(tool.content);
      return new Response(responseStream.getReadableStream());
    }

    // Complex work: Check for async opportunity
    if (classification.tier === RequestTier.COMPLEX_WORK && FEATURES.asyncWork) {
      const asyncOpp = detectAsyncOpportunity(userMessage, classification);

      // Check if user is confirming previous offer
      const lastOffer = sessionManager.getLastOffer(sessionId);
      const isConfirming = lastOffer && detectConfirmation(userMessage);

      if (isConfirming) {
        // User confirmed - queue async work
        const workId = await asyncWorkQueue.enqueue({
          sessionId,
          type: lastOffer.type,
          request: lastOffer.request,
          estimatedDuration: asyncOpp.estimatedDuration
        });

        sessionManager.addActiveWork(sessionId, workId);
        sessionManager.clearLastOffer(sessionId);

        logger.info('üîÑ Async work queued', { workId, sessionId });

        // Add acknowledgment context
        systemPrompt += buildAcknowledgmentContext(lastOffer);

      } else if (asyncOpp.shouldOffer) {
        // Offer async work
        sessionManager.setLastOffer(sessionId, {
          type: asyncOpp.type,
          request: userMessage,
          suggestion: asyncOpp.suggestion
        });

        // Add offer context
        systemPrompt += buildOfferContext(asyncOpp);
      }

      // Check for active work (conversational continuity)
      const activeWork = asyncWorkQueue.getActiveWork(sessionId);
      if (activeWork.length > 0) {
        systemPrompt += buildContinuityContext(activeWork);
      }
    }

    // Generate Noah's response (with all context)
    const response = await generateNoahResponse({
      messages,
      systemPrompt,
      streaming: true
    });

    await responseStream.complete(response.content);
    return new Response(responseStream.getReadableStream());

  } catch (error) {
    logger.error('Chat handler error', { error });
    await responseStream.complete('Sorry, something went wrong. Can you try again?');
    return new Response(responseStream.getReadableStream());
  }
}

// Context builders
function buildNotificationContext(completedWork: AsyncWork[]): string {
  // See Phase 8
}

function buildAcknowledgmentContext(offer: AsyncOffer): string {
  // See Phase 6
}

function buildOfferContext(opportunity: AsyncOpportunity): string {
  // See Phase 5
}

function buildContinuityContext(activeWork: AsyncWork[]): string {
  // See Phase 9
}
```

---

## Testing Strategy

### Unit Tests

```bash
# Phase 1
npm test -- request-classifier.test.ts
npm test -- fast-tool-generator.test.ts

# Phase 2
npm test -- streaming-response.test.ts

# Phase 3
npm test -- async-opportunity-detector.test.ts

# Phase 4
npm test -- session-manager.test.ts

# Phase 5
npm test -- offer-injection.test.ts

# Phase 6
npm test -- confirmation-detector.test.ts

# Phase 7
npm test -- async-work-queue.test.ts

# Phase 8
npm test -- notification.test.ts

# Phase 9
npm test -- conversational-continuity.test.ts
```

### Integration Tests

```bash
# Tier routing
tests/test-tiered-responses.sh

# Async full flow
tests/test-async-work-full-flow.sh

# Conversational continuity
tests/test-conversational-continuity.sh

# Perceptual speed
tests/test-perceptual-speed.sh
```

### Regression Tests

```bash
# Run ALL existing tests with feature flag OFF
ENABLE_ASYNC_WORK=false npm test
ENABLE_ASYNC_WORK=false tests/test-agentic-routing.sh
ENABLE_ASYNC_WORK=false tests/test-noah-excellence.sh
ENABLE_ASYNC_WORK=false tests/test-learning-memory.sh
ENABLE_ASYNC_WORK=false tests/test-security-depth.sh
ENABLE_ASYNC_WORK=false tests/test-performance-optimization.sh

# Verify nothing broke
```

### Manual Testing Scenarios

1. **Normal Conversation (Baseline)**
   - Should work identically to before
   - No async offers
   - Fast response

2. **Simple Tool Request**
   - Fast path (5-15s)
   - No async offer
   - Quality comparable to before

3. **Complex Tool with Async Offer**
   - Offer presented naturally
   - If user ignores, conversation continues
   - If user confirms, work queues

4. **Async Work Flow**
   - User confirms offer
   - Work starts in background
   - Conversation continues
   - Notification appears naturally

5. **Multiple Messages During Async**
   - Send 2-3 messages while work runs
   - Verify Noah stays conversational
   - Verify no awkward reminders

6. **Completed Work Notification**
   - Verify timing feels natural
   - Verify result is available
   - Verify can view tool/research

---

## Rollback Plan

### Immediate Rollback (<1 minute)

```bash
# Disable feature flag
ENABLE_ASYNC_WORK=false

# Restart application
pm2 restart tryitai
# OR
npm run dev
```

**Result:** System behaves identically to before implementation.

### Code Rollback (if flag insufficient)

```bash
# Revert commits
git log --oneline | head -20  # Find commit before async work
git revert <commit-hash>

# OR full reset
git reset --hard <commit-before-async>
```

### Data Cleanup

**None needed** - All state is in-memory. Restart clears everything.

### Testing After Rollback

```bash
# Verify existing tests pass
npm test
tests/test-agentic-routing.sh
tests/test-noah-excellence.sh
```

---

## Success Criteria

### Phase Completion Criteria

| Phase | Success Criteria |
|-------|------------------|
| **Phase 1** | ‚úÖ Classification >90% accuracy, Fast tools <15s, Existing tests pass |
| **Phase 2** | ‚úÖ First response <500ms, Progress updates work, Perceived 2x faster |
| **Phase 3** | ‚úÖ Detection >85% precision, <10% false positives, Logs correct |
| **Phase 4** | ‚úÖ Sessions managed correctly, Expiration works, No leaks |
| **Phase 5** | ‚úÖ Offers natural, Not pushy, Ignore works correctly |
| **Phase 6** | ‚úÖ Detects confirmations >95% precision, Acknowledges naturally |
| **Phase 7** | ‚úÖ Work queues and executes, Timeouts handled, Limits enforced |
| **Phase 8** | ‚úÖ Notifications natural, Timing appropriate, Results available |
| **Phase 9** | ‚úÖ Conversation stays engaged, No awkward mentions, Feels natural |

### Overall Success

**Must Have:**
- ‚úÖ All existing tests pass (flag off)
- ‚úÖ New async tests pass (flag on)
- ‚úÖ Manual UAT scenarios work
- ‚úÖ Performance impact <5%
- ‚úÖ No errors in logs (first week)

**Nice to Have:**
- ‚úÖ User feedback positive
- ‚úÖ Async work completes successfully >90%
- ‚úÖ Users choose async when offered >50%
- ‚úÖ Perceived speed improved (survey)

### Monitoring Metrics

**Track These:**
```typescript
// Async work metrics
{
  async_offers_made: number,
  async_confirmations: number,
  async_work_queued: number,
  async_work_completed: number,
  async_work_failed: number,
  async_work_avg_duration: number,
  async_work_timeout_rate: number,

  // User experience
  messages_during_async_work: number,
  notification_timing_quality: number,
  perceived_speed_improvement: number
}
```

**Alert If:**
- Async work failure rate >10%
- Timeout rate >5%
- Server response time >2x normal
- Memory usage grows unbounded
- Queue backs up (>20 items)

---

## Timeline Summary

| Phase | Duration | Risk | Can Roll Back? |
|-------|----------|------|----------------|
| **Phase 1** | 3-4 days | Low | Yes |
| **Phase 2** | 2-3 days | Low | Yes |
| **Phase 3** | 1-2 days | Low | Yes |
| **Phase 4** | 1 day | Low | Yes |
| **Phase 5** | 1-2 days | Medium | Yes |
| **Phase 6** | 1 day | Low | Yes |
| **Phase 7** | 2-3 days | High | Yes |
| **Phase 8** | 1-2 days | Medium | Yes |
| **Phase 9** | 1 day | Low | Yes |
| **Total** | **12-16 days** | **Managed** | **Always** |

### Recommended Schedule

**Week 1:**
- Day 1-4: Phase 1 (Tiered Response)
- Day 5: Phase 2 start (Perceptual Speed)

**Week 2:**
- Day 1-2: Phase 2 completion + Phase 3 (Detection)
- Day 3: Phase 4 (Session State)
- Day 4-5: Phase 5 (Offer Injection)

**Week 3:**
- Day 1: Phase 6 (Confirmation)
- Day 2-4: Phase 7 (Async Queue - critical)
- Day 5: Phase 8 start (Notification)

**Week 4:**
- Day 1: Phase 8 completion
- Day 2: Phase 9 (Continuity)
- Day 3-4: Buffer for issues/polish
- Day 5: Final testing and documentation

---

## Handoff Checklist

If handing this off to another Claude instance:

**Context They Need:**
- ‚úÖ This document (complete implementation plan)
- ‚úÖ `README.support/TRUE_AGENCY_ROADMAP.md` (agentic architecture)
- ‚úÖ `README.support/NOAH_CHARACTERISTICS_COMPARISON.md` (Noah's personality)
- ‚úÖ `README.support/RECOMMENDATIONS.md` (why this is Priority 0)
- ‚úÖ Current codebase state (they should read existing agent implementations)

**What They Should Do First:**
1. Read this entire document
2. Understand the philosophy (user agency, pragmatic approach)
3. Review existing code (agents, routing, security)
4. Start with Phase 1 (don't skip ahead)
5. Test thoroughly between phases

**What NOT to Do:**
- ‚ùå Don't try to implement "perfect" agentic async (context streaming, bidirectional)
- ‚ùå Don't skip the tiered response (Phase 1) - it's foundational
- ‚ùå Don't forget feature flags - rollback must always work
- ‚ùå Don't change existing agent code - call existing methods
- ‚ùå Don't optimize prematurely - get it working first

---

## Final Notes

### Design Philosophy Summary

1. **User Agency** - They choose when async work happens
2. **Conversational Default** - Most interactions stay conversational
3. **Pragmatic Approach** - Fire-and-forget works for 99% of cases
4. **Perceptual Speed** - Make it feel fast through streaming/progress
5. **Non-Breaking** - Existing functionality preserved 100%

### Why This Approach Works

- **Solves the speed problem** without sacrificing quality
- **Preserves conversational magic** (no silent waiting)
- **Respects user agency** (they decide)
- **Pragmatic complexity** (not over-engineered)
- **Safe rollback** (feature flags, in-memory state)

### Success Looks Like

**User:** "Can you explain React hooks and build an example?"

**Noah:** [starts responding immediately] "Hooks‚Äîgreat topic. Want me to build a demo while we talk?"

**User:** "Sure"

**Noah:** [work starts in background] "On it. So what's your use case?" [conversation continues naturally]

**90 seconds later:** "...and that's why hooks are powerful. By the way, that demo is ready. Check it out?"

**User:** [sees excellent demo that incorporates their use case]

**User Experience:** Feels fast, conversational, and intelligent. Noah is both quick friend AND thoughtful craftsman.

---

**Ready to implement? Start with Phase 1.**
